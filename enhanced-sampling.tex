\section{Assessing Uncertainty in Enhanced Sampling Simulations}
\label{sec:enhanced}

While recent advances in computational hardware have allowed MD simulations of systems with biological relevance to routinely reach timescales ranging from hundreds of \si{\nano\second} to \si{\micro\second}, in many cases this is still not long enough to obtain equilibrated (i.e. Boltzmann-weighted) structural populations.  Intrinsic timescales of the systems may be much longer.
Enhanced sampling methods can be used to obtain well-converged ensembles faster than conventional MD. In general, enhanced sampling methods work through a combination of modifying the underlying energy landscape and/or thermodynamics parameters to increase the rate at which energy barriers are crossed along with some form of reweighting to recover the unbiased ensemble \cite{Zuckerman2011}. However, such methods do not guarantee a converged ensemble, and care must be taken when using and evaluating enhanced sampling methods.

Generally speaking, uncertainty analysis is more challenging for data generated by an enhanced sampling method.
Before performing such a simulation, consider carefully whether the technique is needed, and consult the literature for best practices in setting up a simulation.
Even a straightforward MD simulation requires considerable planning, and the complexity is much greater for enhanced techniques.

\subsection{Replica Exchange Molecular Dynamics}
One of the most popular enhanced sampling methods is replica exchange MD (REMD) \citep{Sugita1999}; see also \cite{Swendsen-1986}. Broadly speaking, REMD consists of running MD simulations a number of non-interacting replicas of a system, each with a different Hamiltonian and/or thermodynamics parameters (e.g., temperature), and periodically exchanging system coordinates between replicas according to a Metropolis criterion.

%%%% Dan Z is commenting out these sections as they are out of scope for error analysis - and would make this document
% quite unwieldy if we made parallel suggestions for all enhanced sampling approaches.
% I encourage you (DRRoe) to include them in a best practices doc on repex
%\subsubsection{Before Starting REMD}
%\begin{itemize}
%  \item Is REMD needed? Can the process be observed multiple times via conventional MD?
%  \item Is dynamic information needed (e.g. diffusion, etc). This information is not easily extracted from REMD simulations.
%  \item Is REMD computationally feasible? Typical implementations of REMD require at least 1 computational node per replica. In general, the number of replicas needed to get reasonable exchange rates is proportional to the square root of the number of degrees of freedom that vary between different replicas.
%  \item What system variable(s) should be modified to increase sampling? Consider what the barriers to sampling are. Temperature is probably the most commonly used variable, but can be problematic: 1) temperature is only good for accelerating certain processes (e.g. protein unfolding but not folding), 2) temperature affects all degrees of freedom of a system and so typically requires large numbers of replicas, especially for explicitly solvated systems. It may be worthwhile to consider a different modification of the Hamiltonian, such as scaling dihedral force constants.
%  \item Replica spacing and exchange acceptance percentage. Replicas need to be spaced such that the overlap in neighboring Hamiltonians is enough to ensure that a certain number of exchange attempts are accepted. Sugita and Okamoto\citep{Sugita1999} originally suggested exchange acceptance be no lower than 10\%, although it is more common in the literature to see target acceptance rate of 20\%. Procedures exist for generating replica temperature "ladders" to achieve a desired exchange acceptance, such as the one by Patriksson and van der Spoel.\citep{Patriksson2008}
%\end{itemize}

%\subsubsection{Running REMD}
%\begin{itemize}
%  \item Number of independent simulations. As with any MD simulation, statistically relevant results for REMD simulations are best achieved when running at least two (and ideally more) independent runs.
%  \item Starting ensemble. In order to ensure that the REMD simulation will be sampling effectively, it is important to have a diverse starting ensemble (i.e. the initial set of coordinates of each replica) so as not to bias the simulation too strongly to any one state. The starting ensemble should ideally represent as much diversity as one hopes to see in the simulation. For example, if one wants to study folding/unfolding, the starting ensemble should be made up of both folded and unfolded structures.
%  \item Exchange frequency to use. There is some debate in the literature. Sindhikara et al. have advocated exchanging as often as possible,\citep{Sindhikara2010} while Abraham and Gready have pointed out that exchanges shorter than then autocorrelation time of the potential energy of the system are not independent.\citep{Abraham2008} In addition, more frequent exchanges can lead to more parallel overhead, reducing computational efficiency. The general consensus in the literature appears to be that 1 ps per exchange attempt is reasonable.
%  \item Coordinate output frequency to use. Because REMD simulations generate coordinates from each replica they produce much more data than conventional MD simulations. As a result it is often beneficial to write trajectory information less frequently than you normally would (e.g. every 10 ps).
%\end{itemize}

%\subsubsection{Assessing REMD Convergence/Efficiency}
In order to assess the results of a REMD simulation, it is important to consider not just the overall convergence of the simulation to the correct Boltzmann-weighted ensemble of structures (via combined clustering, combined PC projection overlap analysis, etc.), but how efficiently the REMD simulation is doing so. These concepts are termed "thermodynamic efficiency" and "mixing efficiency" by Abraham and Gready,\citep{Abraham2008} and it is quite possible to achieve one without the other; both must be assessed. In order for sampling to be efficient, coordinates must be able to move freely in replica space.

Below we will refer to both "coordinate trajectories" and "replica trajectories". A "coordinate trajectory" follows an individual system's continuous trajectory as it traverses replica space (e.g., a system experiencing multiple temperatures as it is exchanged during a temperature REMD simulation). A "replica trajectory" is the sequence of configurations corresponding to a single replica under fixed Hamiltonian and thermodynamic conditions, (e.g., all structures at a temperature of 300 K in a temperature REMD simulation).  Thus, a replica trajectory consists of concatenated coordinate-trajectory segments and \textit{vice versa}.

\begin{itemize}
  \item Exchange acceptance. The exchange acceptance rate (i.e. the number of exchanges divided by the number of exchange attempts) between neighboring replicas should be roughly equivalent to each other and to the target acceptance rate. If the exchange acceptance is too low then replica spacing may need to be decreased or additional replicas used, and vice versa if the exchange acceptance is too high.
  \item Replica round-trips. The time taken for a coordinate trajectory to travel from the lowest replica to the highest and back is called the replica "round trip" time. Over the course of a REMD simulation, any given coordinate trajectory should make multiple round trips. In addition one can look at the average, minimum, and maximum round trip times: these should be roughly equivalent for any given set of coordinates. See e.g. Figure 6 in \citep{Roe2014}.
  \item Replica residence time. The time coordinate trajectory spends at a replica is called the "replica residence time". For replica sampling to be efficient, the average replica residence time for each set of starting coordinates at each replica should be roughly equivalent. See e.g. Figure 7 in Roe et al..\citep{Roe2014}
  \item Distributions of quantities calculated from coordinate trajectories. If all coordinates are moving freely in replica space, they should eventually converge to the same ensemble of structures. Comparing distributions of various quantities from coordinate trajectories can provide a measure of how converged the simulation is. For example, one can compare the distribution of RMSD values of coordinate trajectories to a common reference structure; see e.g. Figure 8 in Henriksen et al..\citep{Henriksen2013} Poor overlap can be an indication that replica efficiency is poor or the simulation is not yet converged.
\end{itemize}

All of the above quantities (replica residence time, round trip time, lifetimes etc) can be calculated with CPPTRAJ,\citep{Roe2013} which is freely available from \url{https://github.com/Amber-MD/cpptraj} or as part of AmberTools (\url{http://ambermd.org}).

It may also be useful to perform multiple REMD runs.  Using the standard uncertainty among runs can quantify uncertainty and provide the basis for a confidence interval with an appropriate coverage factor - see definitions in Sec.\ \ref{sec:scope}.  If the ensembles produced depend significantly on the set of starting configurations, that is a sign of incomplete sampling.

\subsection{Weighted Ensemble simulations}

The weighted ensemble (WE) method orchestrates an ensemble of trajectories that are intermittently pruned or replicated in order to enhance sampling of difficult-to-access regions of configuration space \cite{Huber-1996}.
The final set of trajectories can be visualized as a tree structure based on the occasional replication and pruning events.
WE is an unbiased method that can be used to sample rare transient behavior \cite{Zhang2010a} as well as steady states \cite{Bhatt2010a} including equilibrium \cite{Suarez2014}.

Like other enhanced sampling methods, WE's tree of trajectories has a complex correlation structure requiring care for uncertainty analysis.
It is important to understand the basic theory and limitations of the WE method, as is discussed in a
\href{https://westpa.github.io/westpa/overview.html}{WE overview document}.

From a practical standpoint, the safest way to assess uncertainty in WE simulations is to run multiple instances (which can be seeded from identical or different starting structures depending on the desired calculation) from which a variance and standard uncertainty in any observable can be calculated; see definitions.
Note particularly that WE tracks the time evolution of observables as the system relaxes (perhaps quite slowly) to equilibrium or another steady state \cite{Zhang2010a}; hence, the variance computed in an observable from multiple runs should be based on values at the same time point.

When it is necessary to estimate uncertainty based on a single WE run, the user should treat the (ensemble-weighted) value of an observable measured over time much like an observable in a standard single MD simulation; this is because the correlations in ensemble averages are sequential in time.
First, as discussed in Sec.\ \ref{sec:quick}, the time trace of the observable should be inspected for relaxation to a nearly constant value about which fluctuations occur.
A transient/equilibration period should be removed in analogy to MD - see Sec.\ \ref{sec:equil} - and then best practices for single obervable uncertainties should be followed as described in Sec.\ \ref{sec:specific}.
Despite this rather neat analogy to conventional MD, experience has shown that run-to-run variance in WE simulations of challenging systems can be  large, so multiple runs are  advised.  In the future, variance-reduction techniques may alleviate the need for multiple runs.
