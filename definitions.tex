\subsection{Key Definitions}

In order to make the discussion that follows more precise, we define key terms used in subsequent sections.
We caution that while many of these concepts are familiar, our terminology largely follows the {\it International Vocabulary of Metrology}, a standard that sometimes differs from the conventional language of older works\cite{JCGM:GUM2008,JCGM:VIM2012}.
Such differences are highlighted in the section following the glossary.

%The reader should be familiar with a set of basic statistical and simulation concepts.
%[and we should provide links/refs for each.]

%NOTE FOR DAN S.  In some places I comment on definitions using ``Remarks'' that immediately follow the definition.  Not sure how well this format jibes with the rest of the doc.  Anyways, feel free to merge these remarks into the definitions if you think appropriate.

%NOTE FOR PAUL P. I've restructed the document a bit, applying the "one sentence per line" rule, which makes diff'ing the document easier.

\subsubsection{Glossary of Statistical Terms}
\begin{itemize}
%terms added by PNP and DWS

\item {\bf True value:}  The value of a quantity that is consistent with its definition and is the objective of an ``idealized'' measurement or simulation.
Often the adjective ``true'' is dropped when reference to the definition is clear by context.  \cite{JCGM:GUM2008,JCGM:VIM2012}
%Not sure that the last phrase is entirely consistent with GUM, although I'm not sure this is necessarily a problem.  To a certain extent, we may need to tailor the language of GUM/VIM to the audience at hand.

\medskip

{\bf Remark:} Generally speaking, we use the descriptor ``true value'' in reference to quantities such as the expected value and standard deviation of a simulation output (were we able to run infinitely many simulations).
As these quantities are inherently unknowable, we can only estimate their values and associated uncertainties.


\item {\bf Standard Uncertainty}: Uncertainty in a result (e.g.\ prediction of a true result) as expressed in terms of a standard deviation.

\medskip 

{\bf Remark:} The definition of standard uncertainty does not specify how to calculate the standard deviation.
This choice ultimately rests with the modeler and should be dictated by the details of the uncertainty relevant to the problem at hand.  

\item {\bf Arithmetic mean}: An estimate of the (true) expectation value of a random quantity. The arithmetic mean is given by the formula
  %
  \begin{equation}
    \bar{q} = \dfrac{1}{n} \sum_{k=1}^{n} q_k \label{def:arith_mean}
  \end{equation}
  %
  where $q_j$ is an experimental realization of the random variable and $n$ is the number of samples. 

\medskip 

{\bf Remark:} It is straightforward to show that the arithmetic mean is a random quantity whose expectation value is that same as that of the $q_j$, provided the latter have a common mean.   

\item {\bf Experimental standard deviation}: An estimate of the standard deviation of a random variable, given by the formula
  % 
  \begin{equation}
    s\left(q_k\right) = \sqrt{\dfrac{\sum_{j=1}^n\left(q_j - \bar{q}\right)^2}{n-1}} \label{def:exp_st_dev}
  \end{equation}
  %
  where $q_j$, $\bar{q}$, and $n$ are as defined previously. 
  
\item {\bf Experimental standard deviation of the mean}: An estimate of the standard deviation of the distribution of the arithmetic mean, given by the formula
  % 
  \begin{equation}
    s\left(\bar{q}\right) = \dfrac{s\left(q_k\right)}{\sqrt{n}}. \label{def:exp_st_dev_mean}
  \end{equation}
  %
  
  \medskip
  
  {\bf Remark:} The experimental standard deviation of the mean characterizes the dispersion of the arithmetic mean relative to its expectation.
See \hyperref[def:exp_st_dev]{example link to definition of the experimental standard deviation}.
  
\item {\bf Precision}: The amount of variability in an estimate (e.g.\ based on repeating a given simulation protocol multiple times).  %Better sampling in an individual simulation leads to higher precision.  
%I commented out the last phrase because ``better'' seems a bit vague to me in this context.  Should this comment be placed elsewhere?  
  
  
\item {\bf Accuracy}: The degree to which a result agrees with a reference value.
The latter may be an experimental measurement or the result of a well-sampled simulation.  
  
\item {\bf Raw data}: The numbers that the computer program directly generates as it runs -- typically configurations, and also velocities in molecular dynamics.  
%NOTE FOR DAN S.  Programs also directly compute things like pressure, temperature, volume, etc., which are necessary for controlling thermostats, barostats, etc.  Should we include these in the list of raw data?
  
\item {\bf Derived observables}: Quantities derived from `non-trivial' (and often non-linear) analyses of raw data, such as free energies.

\item {\bf Independent observables}:  Random quantities that are uncorrelated.  More mathematically, quantities $q_j$ and $q_k$ having mean values $\langle q_j \rangle $ and $\langle q_k \rangle$ are uncorrelated if
\begin{align}
\left \langle \left(q_j - \langle q_j \rangle  \right) \left( q_k - \langle q_k \rangle  \right) \right \rangle = 0,
\end{align}
where $\langle \star \rangle$ denotes the (true) expectation value.

\item {\bf Correlated observables}: Random quantities that are not independent.

\item {\bf Correlation time}: In time-series data of a random quantity $q(t)$ (e.g.\ a physical property from a MC or MD trajectory), this is the time $\tau$ over which $q(t)$ and $q(t+\tau)$ remain correlated.  

\medskip

{\bf Remark:} Generally speaking, MC and MD trajectories generate new configurations from preceding ones.
Thus, the correlation time can be interpreted as the time over which the system retains memory of its previous states.
Such correlations are often {\bf stationary}, meaning that $\tau$ is independent of $t$.
Roughly speaking, the total simulation time divided by the longest correlation time yields an estimate of the number of {\it independent} samples generated by a simulation.


%The time over which realizations of a random quantity indexed by a time-series  (e.g.\ a physical property from a Monte Carlo or molecular dynamics trajectory) retain ``memory'' of one another, since each configuration is generated from the preceding one.  Roughly, the total simulation time divided by the (longest) correlation time gives an estimate of the number of \emph{independent} samples that will govern overall statistical quality of the data.

\item {\bf Confidence interval}: A statistically derived pair of lower and upper bounds between which the expectation value of a random quantity is likely to fall, as quantified by a percentage.




  
% Older versions
%\item Precision: The amount of variability in an estimate (based on repeating a given simulation protocol multiple times).
%      Better sampling in an individual simulation leads to higher precision.
%      The standard error of the mean is usually the key measure of the \emph{scale} of the statistical uncertainty - i.e., %precision.
%    \item Confidence Interval: A statistically derived pair of minimum and maximum values within which the mean of an observable is likely to fall, as quantified by a percentage.  Note that useful confidence intervals (e.g., 90 or 95\%) tend to be roughly \emph{four times} the standard error of the mean (from minimum to maximum).
%    \item Accuracy: The degree of agreement with a reference value, which may be an experimental measurement or the result of a %well-sampled simulation.
%    \item Raw data: The numbers that the computer program directly generates as it runs -- typically configurations, and also %velocities in molecular dynamics.
%    \item Derived observables:  Quantities derived from `non-trivial' analyses of raw data, such as free energies.
%    \item Correlation time: The time over which samples/configurations in a MC or MD trajectory retain some "memory" of one another, since each configuration is generated from the preceding one.  Roughly, the total simulation time divided by the (longest) correlation time gives an estimate of the number of \emph{independent} samples that will govern overall statistical quality of the data.

\end{itemize}

\subsubsection{Discussion of terminology}

As surveyed by Refs.~\cite{JCGM:GUM2008,JCGM:VIM2012}, the discussion that originally motivated many of theses definitions is rather philosophical.
Nonetheless, it bears repeating here, if only to force a level of honesty regarding what we can actually hope to achieve with simulations.  

The fundamental idea underpinning this disucssion is the observation that true values are inherently unknowable.
As an added twist, the {\it Uncertainty Approach} advocated by Ref.~\cite{JCGM:GUM2008} also points out that the {\it definitions of true values may be imprecise,} so that the latter are in fact not even uniquely defined.\footnote{The Guide to the Expression of Uncertainty in Measurement (GUM) treats this definitional uncertainty as negligible compared to other sources.
However, the notion of definitional uncertainty is worth revisiting in the context of simulated data.
For example, we are aware of at least one situation in which the large scale of noise in simulated data (as compared with experiments) induces subjectivity in the definition of the glass-transition temperature, which ultimately affects uncertainties in a non-trivial way.
See Ref.~\cite{Patrone1} and \textcolor{red}{Cite TG doc}.} As such, assignments of ``error'' are impossible to make, since these are defined relative to the true value.
Rather, statistical analyses are better interpreted as quantifying our state of knowledge, e.g.\ our ability to confidently state that the the ``true'' mean is within some interval.  

From a practical standpoint, this leads one to revisit definitions of uncertainty as defined, for example, by Eqs.~\eqref{eq:def:exp_st_dev_mean}.
Conventionally this has gone by the name ``standard error,'' but in keeping with the perspective already laid out, we advocate the use of experimental standard deviation of the mean.
To maintain consistency with the VIM and GUM, we also use ``sample mean'' and ``sample standard deviation'' with their counterparts ``arithmetic mean'' and ``experimental standard deviation.''
The reader should be aware that this older language is still used frequently throughout the literature.


%Table of equivalencies

%Arithmetic mean = ``sample mean''\\
%Experimental standard deviation: ``sample standard deviation''\\
%Experimental standard deviation of the mean: ``standard error''\\

