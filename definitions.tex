\subsection{Key Definitions}

In order to make the discussion that follows more precise, we define key terms used in subsequent sections.
We caution that while many of these concepts are familiar, our terminology follows the {\it International Vocabulary of Metrology} (VIM)\citep{JCGM:VIM2012}, a standard that sometimes differs from the conventional or common language of engineering statistics. 
For additional information about or clarification of the statistical meaning of terms in the VIM, we suggest that readers consult the {\it Guide to the expression of uncertainty in measurement} (GUM)\citep{JCGM:GUM2008}.
For clarity, we highlight differences between conventional terms and the VIM in the section following the glossary.
In cases of lexical ambiguity, we hold to the definition of terms as given in the VIM.

%The reader should be familiar with a set of basic statistical and simulation concepts.
%[and we should provide links/refs for each.]

%NOTE FOR DAN S.  In some places I comment on definitions using ``Remarks'' that immediately follow the definition.  Not sure how well this format jibes with the rest of the doc.  Anyways, feel free to merge these remarks into the definitions if you think appropriate.

%NOTE FOR PAUL P. I've restructed the document a bit, applying the "one sentence per line" rule, which makes diff'ing the document easier.

% Reply to Dan S.: One sentence rule works for me

\subsubsection{Glossary of Statistical Terms}
\begin{itemize}
%terms added by PNP and DWS

\item {\bf Random quantity}: A quantity whose numerical value is inherently unknowable or unpredictable.

\smallskip

\textbf{\textit{Remark:}}  Informally speaking, we assume that a random quantity can be described in terms of a mean (or expected) value and a dispersion.  The latter characterizes the extent to which a {\it realization} of the random quantity differs from the mean.  More formally, we assume that the probability of a random variable $X$ taking value $x$ is given by $P(x)dx$, where $P(x)$ is a probably density and $dx$ is an infinitesimal width about $x$.

\smallskip

\textbf{\textit{Remark:}} Virtually all simulation tools (even those using quasi-random number generators) are deterministic.  As such, the output of any given simulation is never truly random, since it is the composition of knowable and predictable calculations.  However, it is generally infeasible to reproduce simulated calculations by hand, so that these are {\it in practice} unknowable.  Moreover, the chaotic nature of typical simulated systems leads to a situation in which the frequency of a given system configuration is well described by probability densities of statistical mechanics.  See Ref.~\cite{Leimkuhler} for more discussion of this rather deep point.

\item {\bf True value:}  The value of a quantity that is consistent with its definition and is the objective of an idealized measurement or simulation.

\smallskip
\textbf{\textit{Remark:}} Often the adjective ``true'' is dropped when reference to the definition is clear by context. \citep{JCGM:GUM2008,JCGM:VIM2012}
%Not sure that the last phrase is entirely consistent with GUM, although I'm not sure this is necessarily a problem.  To a certain extent, we may need to tailor the language of GUM/VIM to the audience at hand.
\smallskip

\textbf{\textit{Remark:}} Generally speaking, we use the descriptor ``true value'' in reference to quantities such as the expected value and standard deviation of a simulation output (were we able to run infinitely many simulations).
As these quantities are inherently unknowable, we can only estimate their values and associated uncertainties.

\item {\bf Standard Uncertainty}: Uncertainty in a result (e.g.\ prediction of a true value) as expressed in terms of a standard deviation.
\smallskip 

\textbf{\textit{Remark:}} The definition of standard uncertainty does not specify how to calculate the standard deviation.
This choice ultimately rests with the modeler and should be dictated by the details of the uncertainty relevant to the problem at hand.  

\item {\bf Arithmetic mean}: An estimate of the (true) expectation value of a random quantity. The arithmetic mean is given by the formula
  %
  \begin{equation}
    \bar{q} = \dfrac{1}{n} \sum_{k=1}^{n} q_k \label{def:arith_mean}
  \end{equation}
  %
  where $q_j$ is an experimental or simulated realization of the random variable and $n$ is the number of samples. 
\smallskip 
%PNP Note: I added "or simulated" after "experimental" in the line above

\textbf{\textit{Remark:}} It is straightforward to show that the arithmetic mean is a random quantity whose expectation value is that same as that of the $q_j$, provided the latter have a common mean.

\item {\bf Experimental standard deviation}: An estimate of the (true) standard deviation of a random variable, given by the formula
  % 
  \begin{equation}
    s\left(q_k\right) = \sqrt{\dfrac{\sum_{j=1}^n\left(q_j - \bar{q}\right)^2}{n-1}} \label{def:exp_st_dev}
  \end{equation}
  %
  where $q_j$, $\bar{q}$, and $n$ are as defined previously. 
  
\item {\bf Experimental standard deviation of the mean}: An estimate of the standard deviation of the distribution of the arithmetic mean, given by the formula
  % 
  \begin{equation}
    s\left(\bar{q}\right) = \dfrac{s\left(q_k\right)}{\sqrt{n}}. \label{def:exp_st_dev_mean}
  \end{equation}
  %
  \smallskip
  
\textbf{\textit{Remark:}} The experimental standard deviation of the mean characterizes the dispersion of the arithmetic mean relative to its expectation.
See \hyperref[def:exp_st_dev]{example link to definition of the experimental standard deviation}.
  
\item {\bf Precision}: The amount of variability in an estimate (e.g., based on repeating a given simulation protocol multiple times).  %Better sampling in an individual simulation leads to higher precision.  
%I commented out the last phrase because ``better'' seems a bit vague to me in this context.  Should this comment be placed elsewhere?  
  
  
\item {\bf Accuracy}: The degree to which a result agrees with a reference value.
The latter may be an experimental measurement or the result of a well-sampled simulation.  
  
\item {\bf Raw data}: The numbers that the computer program directly generates as it proceeds through a sequence of states [the phase-space trajectory for molecular dynamics (MD) or the Markov chain for Monte Carlo (MC)].
For example, a MC simulation generates a sequence of configurations, for which there are associated properties such as the instantaneous pressure, temperature, volume, etc.
% NOTE FOR DAN S.  Programs also directly compute things like pressure, temperature, volume, etc., which are necessary for controlling thermostats, barostats, etc.  Should we include these in the list of raw data?
% DWS REPLY: How is this modification?
% PNP REPLY: Overall fine.  I changed Monte Carlo to MD in the last sentence.  Do MC simulations have associated pressures?  I always thought that could only be computed in the context of a dynamical simulation.
% DWS REPLY2: I switched it back to MC - one of my objectives in this paper to make sure it is not too MD-centric. Aside: yes, you can calculate an instantaneous pressure in MC via the molecular virial if using a fixed-N ensemble.
  
\item {\bf Derived observables}: Quantities derived from `non-trivial' (and often non-linear) analyses of raw data, e.g., properties that may not be computed for a single configuration such as free energies.
  
\item {\bf Indepent observables}: Random quantities $x$ and $y$ for which the joint probability density can be written as a product of individual probability densities $P(x,y)=P(x)P(y)$.  
  
\item {\bf (Linearly) Uncorrelated observables}:  If quantities $q_j$ and $q_k$ have mean values $\left< q_j \right> $ and $\left< q_k \right>$, then $q_j$ and $q_k$ are linearly uncorrelated if
% 
\begin{equation}
  \left< \left(q_j - \left<q_j\right> \right) \left(q_k - \left<q_k\right> \right) \right>=0
\end{equation}
%
where $\left< \star \right>$ denotes the (true) expectation value.

\smallskip

\textbf{\textit{Remark:}} Independence of random variables implies that they are linearly uncorrelated.  The converse, however, is not true.  

\smallskip

\textbf{\textit{Remark:}} In practice, it is easier to (empirically) show that random variables are uncorrelated than independent.  However, linear correlations are often all that are needed to arrive at uncertainty estimates for various quantities.  See, e.g.\ the discussion of correlation times and autocorrelation analyses.
%PNP: where is that discussion?



\item {\bf Correlated observables}: Random quantities that are not independent.

\item {\bf Correlation time}: In time-series data of a random quantity $q(t)$ (e.g.\ a physical property from a MC or MD trajectory), this is the time $\tau$ over which $q(t)$ and $q(t+\tau)$ remain (linearly) correlated.

\smallskip

\textbf{\textit{Remark:}} Generally speaking, MC and MD trajectories generate new configurations from preceding ones.
Thus, the correlation time can be interpreted as the time over which the system retains memory of its previous states.
Such correlations are often {\bf stationary}, meaning that $\tau$ is independent of $t$.
Roughly speaking, the total simulation time divided by the longest correlation time yields an estimate of the number of {\it uncorrelated} samples generated by a simulation.


%The time over which realizations of a random quantity indexed by a time-series (e.g.\ a physical property from a Monte Carlo or molecular dynamics trajectory) retain ``memory'' of one another, since each configuration is generated from the preceding one. Roughly, the total simulation time divided by the (longest) correlation time gives an estimate of the number of \emph{independent} samples that will govern overall statistical quality of the data.

\item {\bf Two-sided confidence interval}: A statistically derived bound pair of lower and upper bounds between which the (true) expectation value of a random quantity is likely to fall, as quantified by a {\it confidence level} (typically given as a percentage, e.g., 95~\%). The confidence level, in conjunction with the sample size, determines the {\it coverage factor}, which is multiplied by \hyperref[def:exp_st_dev_mean]{$s\left(\bar{q}\right)$} to assign the bounds of the confidence interval.

% Older versions
%\item Precision: The amount of variability in an estimate (based on repeating a given simulation protocol multiple times).
%      Better sampling in an individual simulation leads to higher precision.
%      The standard error of the mean is usually the key measure of the \emph{scale} of the statistical uncertainty - i.e., %precision.
%    \item Confidence Interval: A statistically derived pair of minimum and maximum values within which the mean of an observable is likely to fall, as quantified by a percentage.  Note that useful confidence intervals (e.g., 90 or 95\%) tend to be roughly \emph{four times} the standard error of the mean (from minimum to maximum).
%    \item Accuracy: The degree of agreement with a reference value, which may be an experimental measurement or the result of a %well-sampled simulation.
%    \item Raw data: The numbers that the computer program directly generates as it runs -- typically configurations, and also %velocities in molecular dynamics.
%    \item Derived observables:  Quantities derived from `non-trivial' analyses of raw data, such as free energies.
%    \item Correlation time: The time over which samples/configurations in a MC or MD trajectory retain some "memory" of one another, since each configuration is generated from the preceding one.  Roughly, the total simulation time divided by the (longest) correlation time gives an estimate of the number of \emph{independent} samples that will govern overall statistical quality of the data.

\end{itemize}

\subsubsection{Discussion of terminology}

As surveyed by Refs.~\citep{JCGM:GUM2008,JCGM:VIM2012}, the discussion that originally motivated many of theses definitions is rather philosophical.
Nonetheless, it bears repeating here, if only to force a level of honesty regarding what we can actually hope to achieve with simulations.

The fundamental idea underpinning this discussion is the observation that true values are inherently unknowable.
As an added twist, the {\it Uncertainty Approach} advocated by Ref.~\citep{JCGM:GUM2008} also points out that the {\it definitions of true values may be imprecise,} so that the latter are in fact not even uniquely defined.\footnote{The GUM treats this definitional uncertainty as negligible compared to other sources.
However, the notion of definitional uncertainty is worth revisiting in the context of simulated data.
For example, we are aware of at least one situation in which the large scale of noise in simulated data (as compared with experiments) induces subjectivity in the definition of the glass-transition temperature, which ultimately affects uncertainties in a non-trivial way.
See Ref.~\citep{patrone1} and \textcolor{red}{Cite TG doc}.}
As such, assignments of ``error'' are impossible to make, since these are defined relative to the true value.
Rather, statistical analyses are better interpreted as quantifying our state of knowledge, e.g., our ability to confidently state that the the ``true'' mean is within some interval.

From a practical standpoint, this leads one to revisit definitions of uncertainty as defined, for example, by Eqs.~\ref{def:exp_st_dev} and \ref{def:exp_st_dev_mean}.
Conventionally this has gone by the name ``standard error,'' but in keeping with the perspective already laid out, we advocate the use of \hyperref[def:exp_st_dev_mean]{experimental standard deviation of the mean}.
To maintain consistency with the VIM and GUM, we also use ``sample mean'' and ``sample standard deviation'' with their counterparts ``arithmetic mean'' and ``experimental standard deviation.''
The reader should be aware that this older language is still used frequently throughout the literature.


%Table of equivalencies

%Arithmetic mean = ``sample mean''\\
%Experimental standard deviation: ``sample standard deviation''\\
%Experimental standard deviation of the mean: ``standard error''\\

